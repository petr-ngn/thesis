\contentsline {chapter}{List of Tables}{viii}{section*.9}%
\contentsline {chapter}{List of Figures}{x}{section*.11}%
\contentsline {chapter}{Acronyms}{xii}{section*.13}%
\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}%
\contentsline {chapter}{\numberline {2}Theoretical Background}{2}{chapter.2}%
\contentsline {section}{\numberline {2.1}Credit Risk}{2}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Regulation}{3}{subsection.2.1.1}%
\contentsline {subsubsection}{Basel II/III}{3}{section*.15}%
\contentsline {subsubsection}{Standardized Approach}{3}{section*.16}%
\contentsline {subsubsection}{IFRS 9}{3}{section*.17}%
\contentsline {subsection}{\numberline {2.1.2}Credit Scoring}{3}{subsection.2.1.2}%
\contentsline {subsubsection}{Application Scoring}{4}{section*.18}%
\contentsline {subsubsection}{Behavioral Scoring}{4}{section*.19}%
\contentsline {section}{\numberline {2.2}Machine Learning Terminology}{4}{section.2.2}%
\contentsline {section}{\numberline {2.3}Algorithms}{5}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Logistic Regression}{5}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Decision Tree}{7}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Naive Bayes}{10}{subsection.2.3.3}%
\contentsline {subsection}{\numberline {2.3.4}K-Nearest Neighbors}{12}{subsection.2.3.4}%
\contentsline {subsection}{\numberline {2.3.5}Random Forest}{14}{subsection.2.3.5}%
\contentsline {subsection}{\numberline {2.3.6}Gradient Boosting}{15}{subsection.2.3.6}%
\contentsline {subsection}{\numberline {2.3.7}Support Vector Machine}{16}{subsection.2.3.7}%
\contentsline {subsection}{\numberline {2.3.8}Neural Network}{18}{subsection.2.3.8}%
\contentsline {section}{\numberline {2.4}Evaluation Metrics}{21}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Confusion Matrix and Derived Metrics}{21}{subsection.2.4.1}%
\contentsline {subsubsection}{Accuracy}{22}{section*.27}%
\contentsline {subsubsection}{Recall}{23}{section*.28}%
\contentsline {subsubsection}{Precision}{23}{section*.29}%
\contentsline {subsubsection}{F1 Score}{24}{section*.30}%
\contentsline {subsubsection}{Matthews Correlation Coefficient}{24}{section*.31}%
\contentsline {subsection}{\numberline {2.4.2}ROC Curve and AUC}{25}{subsection.2.4.2}%
\contentsline {subsubsection}{ROC Curve}{25}{section*.32}%
\contentsline {subsubsection}{AUC}{26}{section*.34}%
\contentsline {subsection}{\numberline {2.4.3}Kolmogorov-Smirnov Distance}{27}{subsection.2.4.3}%
\contentsline {subsection}{\numberline {2.4.4}Somer's D}{28}{subsection.2.4.4}%
\contentsline {subsection}{\numberline {2.4.5}Brier Score Loss}{29}{subsection.2.4.5}%
\contentsline {subsection}{\numberline {2.4.6}Log Loss}{29}{subsection.2.4.6}%
\contentsline {section}{\numberline {2.5}ADASYN Oversampling}{30}{section.2.5}%
\contentsline {section}{\numberline {2.6}Optimal Binning}{33}{section.2.6}%
\contentsline {section}{\numberline {2.7}Hyperparameter Bayesian Optimization}{35}{section.2.7}%
\contentsline {section}{\numberline {2.8}Forward Sequential Feature Selection}{37}{section.2.8}%
\contentsline {section}{\numberline {2.9}Theoretical Summary}{39}{section.2.9}%
\contentsline {chapter}{\numberline {3}Literature Review}{40}{chapter.3}%
\contentsline {section}{\numberline {3.1}Hypotheses}{44}{section.3.1}%
\contentsline {chapter}{\numberline {4}Empirical Analysis - Machine Learning Implementation}{47}{chapter.4}%
\contentsline {section}{\numberline {4.1}Repository and Environment Structure}{49}{section.4.1}%
\contentsline {section}{\numberline {4.2}Data Exploration}{52}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Data Set Description}{52}{subsection.4.2.1}%
\contentsline {subsection}{\numberline {4.2.2}Distribution Analysis}{54}{subsection.4.2.2}%
\contentsline {subsubsection}{Default Distribution}{54}{section*.47}%
\contentsline {subsubsection}{Numeric Features' Distribution}{55}{section*.49}%
\contentsline {subsubsection}{Categorical Features' Distribution}{59}{section*.52}%
\contentsline {subsection}{\numberline {4.2.3}Association Analysis}{60}{subsection.4.2.3}%
\contentsline {subsubsection}{Association between default status and numeric features}{60}{section*.54}%
\contentsline {subsubsection}{Association between default status and categorical features}{62}{section*.56}%
\contentsline {subsubsection}{Association between default status and missing values}{62}{section*.58}%
\contentsline {subsubsection}{Missing Values Association}{63}{section*.60}%
\contentsline {subsubsection}{Multicolinearity Analysis}{65}{section*.63}%
\contentsline {section}{\numberline {4.3}Data Preprocessing}{67}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Data Split and ADASYN Oversampling}{67}{subsection.4.3.1}%
\contentsline {subsection}{\numberline {4.3.2}Optimal Binning and Weight--of--Evidence}{71}{subsection.4.3.2}%
\contentsline {section}{\numberline {4.4}Modelling}{74}{section.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Hyperparameter Bayesian Optimization}{74}{subsection.4.4.1}%
\contentsline {subsubsection}{Logistic Regression}{75}{section*.69}%
\contentsline {subsubsection}{Decision Tree}{76}{section*.71}%
\contentsline {subsubsection}{Gaussian Naive Bayes}{76}{section*.73}%
\contentsline {subsubsection}{K--Nearest Neighbors}{77}{section*.75}%
\contentsline {subsubsection}{Random Forest}{77}{section*.77}%
\contentsline {subsubsection}{Gradient Boosting}{78}{section*.79}%
\contentsline {subsubsection}{Support Vector Machine}{79}{section*.81}%
\contentsline {subsubsection}{Multi--Layer Percepton}{80}{section*.83}%
\contentsline {subsection}{\numberline {4.4.2}Sequential Feature Selection}{81}{subsection.4.4.2}%
\contentsline {subsection}{\numberline {4.4.3}Model Selection}{84}{subsection.4.4.3}%
\contentsline {subsubsection}{Metrics Space}{85}{section*.88}%
\contentsline {subsubsection}{Model Selection Results}{87}{section*.90}%
\contentsline {subsection}{\numberline {4.4.4}Model Recalibration}{101}{subsection.4.4.4}%
\contentsline {section}{\numberline {4.5}Model Evaluation}{102}{section.4.5}%
\contentsline {subsection}{\numberline {4.5.1}Model Performance Assessment}{102}{subsection.4.5.1}%
\contentsline {subsection}{\numberline {4.5.2}Model Explainability}{105}{subsection.4.5.2}%
\contentsline {section}{\numberline {4.6}Machine Learning Deployment}{109}{section.4.6}%
\contentsline {subsection}{\numberline {4.6.1}Final Model Recalibration}{109}{subsection.4.6.1}%
\contentsline {subsection}{\numberline {4.6.2}Flask and HTML Web Application}{109}{subsection.4.6.2}%
\contentsline {chapter}{\numberline {5}Hypotheses' Testing and Future Recommendations}{114}{chapter.5}%
\contentsline {section}{\numberline {5.1}Hypotheses' Testing}{114}{section.5.1}%
\contentsline {section}{\numberline {5.2}Future Recommendations}{116}{section.5.2}%
\contentsline {chapter}{\numberline {6}Conclusion}{119}{chapter.6}%
\contentsline {chapter}{Bibliography}{120}{chapter.6}%
\contentsline {chapter}{\numberline {A}Additional Figures and Tables}{I}{appendix.A}%
\contentsline {chapter}{\numberline {B}Source Codes}{II}{appendix.B}%
\contentsline {section}{\numberline {B.1}Python Notebook Code (\lstinline {Masters_Thesis.ipynb})}{II}{section.B.1}%
\contentsline {subsection}{\numberline {B.1.1}Data Exploration}{IV}{subsection.B.1.1}%
\contentsline {subsection}{\numberline {B.1.2}Data Preprocessing}{XXVI}{subsection.B.1.2}%
\contentsline {subsection}{\numberline {B.1.3}Modelling}{XLVI}{subsection.B.1.3}%
\contentsline {subsection}{\numberline {B.1.4}Evaluation}{LXXXII}{subsection.B.1.4}%
\contentsline {section}{\numberline {B.2}Back--end: Flask Web Application Code (\lstinline {app.py})}{XCIII}{section.B.2}%
\contentsline {section}{\numberline {B.3}Front--end: HTML Code}{C}{section.B.3}%
\contentsline {subsection}{\numberline {B.3.1}Application Form (\lstinline {index.html})}{C}{subsection.B.3.1}%
\contentsline {subsection}{\numberline {B.3.2}Application Results (\lstinline {results.html})}{CVI}{subsection.B.3.2}%
