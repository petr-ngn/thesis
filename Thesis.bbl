\begin{thebibliography}{56}
\newcommand{\enquote}[1]{``#1''}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Adeodato \& Melo(2016)}]{adeodato2016equivalence}
\textsc{Adeodato}, P.~J. \& S.~B. \textsc{Melo} (2016): \enquote{On the
  equivalence between kolmogorov-smirnov and roc curve metrics for binary
  classification.}
\newblock \emph{arXiv preprint arXiv:1606.00496} .

\bibitem[{Ayyadevara(2018)}]{ayyadevara2018pro}
\textsc{Ayyadevara}, V.~K. (2018): \enquote{Pro machine learning algorithms.}
\newblock \emph{Apress: Berkeley, CA, USA} .

\bibitem[{Bera \emph{et~al.}(2021)Bera, Pratap, \&
  Verma}]{bera2021dimensionality}
\textsc{Bera}, D., R.~\textsc{Pratap}, \& B.~D. \textsc{Verma} (2021):
  \enquote{Dimensionality reduction for categorical data.}
\newblock \emph{IEEE Transactions on Knowledge and Data Engineering} .

\bibitem[{Bischl \emph{et~al.}(2023)Bischl, Binder, Lang, Pielok, Richter,
  Coors, Thomas, Ullmann, Becker, Boulesteix
  \emph{et~al.}}]{bischl2023hyperparameter}
\textsc{Bischl}, B., M.~\textsc{Binder}, M.~\textsc{Lang}, T.~\textsc{Pielok},
  J.~\textsc{Richter}, S.~\textsc{Coors}, J.~\textsc{Thomas},
  T.~\textsc{Ullmann}, M.~\textsc{Becker}, A.-L. \textsc{Boulesteix}
  \emph{et~al.} (2023): \enquote{Hyperparameter optimization: Foundations,
  algorithms, best practices, and open challenges.}
\newblock \emph{Wiley Interdisciplinary Reviews: Data Mining and Knowledge
  Discovery} \textbf{13(2)}: p. e1484.

\bibitem[{Bol{\'o}n-Canedo \emph{et~al.}(2015)Bol{\'o}n-Canedo,
  S{\'a}nchez-Maro{\~n}o, \& Alonso-Betanzos}]{bolon2015feature}
\textsc{Bol{\'o}n-Canedo}, V., N.~\textsc{S{\'a}nchez-Maro{\~n}o}, \&
  A.~\textsc{Alonso-Betanzos} (2015): \emph{Feature selection for
  high-dimensional data}.
\newblock Springer.

\bibitem[{Bonaccorso(2020)}]{bonaccorso2020mastering}
\textsc{Bonaccorso}, G. (2020): \emph{Mastering Machine Learning Algorithms:
  Expert techniques for implementing popular machine learning algorithms,
  fine-tuning your models, and understanding how they work}.
\newblock Packt Publishing Ltd.

\bibitem[{Boughorbel \emph{et~al.}(2017)Boughorbel, Jarray, \&
  El-Anbari}]{boughorbel2017optimal}
\textsc{Boughorbel}, S., F.~\textsc{Jarray}, \& M.~\textsc{El-Anbari} (2017):
  \enquote{Optimal classifier for imbalanced data using matthews correlation
  coefficient metric.}
\newblock \emph{PloS one} \textbf{12(6)}: p. e0177678.

\bibitem[{Brabec \emph{et~al.}(2020)Brabec, Kom{\'a}rek, Franc, \&
  Machlica}]{brabec2020model}
\textsc{Brabec}, J., T.~\textsc{Kom{\'a}rek}, V.~\textsc{Franc}, \&
  L.~\textsc{Machlica} (2020): \enquote{On model evaluation under non-constant
  class imbalance.}
\newblock In \enquote{Computational Science--ICCS 2020: 20th International
  Conference, Amsterdam, The Netherlands, June 3--5, 2020, Proceedings, Part IV
  20,} pp. 74--87. Springer.

\bibitem[{Brownlee(2020)}]{Brownlee2020}
\textsc{Brownlee}, J. (2020): \enquote{Recursive feature elimination (rfe) for
  feature selection in python.}
\newblock Retrieved April 28, 2023.

\bibitem[{Brownlee(2021)}]{brownlee2021failure}
\textsc{Brownlee}, J. (2021): \enquote{Failure of classification accuracy for
  imbalanced class distributions.}
\newblock \emph{MachineLearningMastery.com} .

\bibitem[{Charu(2018)}]{charu2018neural}
\textsc{Charu}, C.~A. (2018): \enquote{Neural networks and deep learning: a
  textbook.}

\bibitem[{Chicco \& Jurman(2020)}]{chicco2020advantages}
\textsc{Chicco}, D. \& G.~\textsc{Jurman} (2020): \enquote{The advantages of
  the matthews correlation coefficient (mcc) over f1 score and accuracy in
  binary classification evaluation.}
\newblock \emph{BMC genomics} \textbf{21}: pp. 1--13.

\bibitem[{Cichosz(2014)}]{cichosz2014data}
\textsc{Cichosz}, P. (2014): \emph{Data mining algorithms: explained using R}.
\newblock John Wiley \& Sons.

\bibitem[{Comotto(2022)}]{comotto2022evaluation}
\textsc{Comotto}, F. (2022): \enquote{Evaluation metrics: Leave your comfort
  zone and try mcc and brier score.}
\newblock Medium.
\newblock Retrieved April 30, 2023.

\bibitem[{Dembla(2020)}]{dembla2020intuition}
\textsc{Dembla}, G. (2020): \enquote{Intuition behind log-loss score.}
\newblock Medium.
\newblock Retrieved April 30, 2023.

\bibitem[{Dias \emph{et~al.}(2018)Dias, Experian, Melissa~Forti, Witarsa, \&
  Experian}]{dias2018comparison}
\textsc{Dias}, P., S.~\textsc{Experian}, B.~\textsc{Melissa~Forti},
  M.~\textsc{Witarsa}, \& S.~\textsc{Experian} (2018): \enquote{A comparison of
  gradient boosting with logistic regression in practical cases.}
\newblock In \enquote{URL: https://www. sas.
  com/content/dam/SAS/support/en/sasglobal-forum-proceedings/2018/1857-2018.
  pdf,} .

\bibitem[{Dilmegani(2017)}]{Dilmegani2017}
\textsc{Dilmegani}, C. (2017): \enquote{Dark side of neural networks explained
  [2023].}
\newblock AIMultiple.
\newblock Retrieved April 30, 2023.

\bibitem[{Doumpos \emph{et~al.}(2019)Doumpos, Lemonakis, Niklis, \&
  Zopounidis}]{doumpos2019analytical}
\textsc{Doumpos}, M., C.~\textsc{Lemonakis}, D.~\textsc{Niklis}, \&
  C.~\textsc{Zopounidis} (2019): \enquote{Analytical techniques in the
  assessment of credit risk.}
\newblock \emph{EURO Advanced Tutorials on Operational Research. Cham: Springer
  International Publishing.[Google Scholar]} .

\bibitem[{Drahokoupil(2022)}]{drahokoupil2022application}
\textsc{Drahokoupil}, J. (2022): \enquote{Application of the xgboost algorithm
  and bayesian optimization for the bitcoin price prediction during the
  covid-19 period.}
\newblock \emph{FFA Working Papers} \textbf{4}: p. Article 2022.006.

\bibitem[{Esposito \emph{et~al.}(2021)Esposito, Landrum, Schneider, Stiefl, \&
  Riniker}]{esposito2021ghost}
\textsc{Esposito}, C., G.~A. \textsc{Landrum}, N.~\textsc{Schneider},
  N.~\textsc{Stiefl}, \& S.~\textsc{Riniker} (2021): \enquote{Ghost: adjusting
  the decision threshold to handle imbalanced data in machine learning.}
\newblock \emph{Journal of Chemical Information and Modeling} \textbf{61(6)}:
  pp. 2623--2640.

\bibitem[{Fluss \emph{et~al.}(2005)Fluss, Faraggi, \&
  Reiser}]{fluss2005estimation}
\textsc{Fluss}, R., D.~\textsc{Faraggi}, \& B.~\textsc{Reiser} (2005):
  \enquote{Estimation of the youden index and its associated cutoff point.}
\newblock \emph{Biometrical Journal: Journal of Mathematical Methods in
  Biosciences} \textbf{47(4)}: pp. 458--472.

\bibitem[{Gauhar(2020)}]{gauhar2020decision}
\textsc{Gauhar}, N. (2020): \enquote{Decision tree: A classification
  algorithm.}
\newblock
  \url{https://learnwithgauhar.com/decision-tree-a-classification-algorithm/}.
\newblock Accessed on April 30, 2023.

\bibitem[{Han \emph{et~al.}(2011)Han, Kamber, \& Pei}]{han2011data}
\textsc{Han}, J., M.~\textsc{Kamber}, \& J.~\textsc{Pei} (2011): \emph{Data
  Mining: Concepts and Techniques}.
\newblock Morgan Kaufmann, 3rd edition.

\bibitem[{He \emph{et~al.}(2008)He, Bai, Garcia, \& Li}]{adasynhaibo}
\textsc{He}, H., Y.~\textsc{Bai}, E.~A. \textsc{Garcia}, \& S.~\textsc{Li}
  (2008): \enquote{Adasyn: Adaptive synthetic sampling approach for imbalanced
  learning.}
\newblock In \enquote{2008 IEEE International Joint Conference on Neural
  Networks (IEEE World Congress on Computational Intelligence),} pp.
  1322--1328.

\bibitem[{He \& Ma(2013)}]{ma2013imbalanced}
\textsc{He}, H. \& Y.~\textsc{Ma} (2013): \emph{Imbalanced Learning:
  Foundations, Algorithms, and Applications}.
\newblock Wiley-IEEE Press.

\bibitem[{de~Hond \emph{et~al.}(2023)de~Hond, Kant, Fornasa, Cin{\`a}, Elbers,
  Thoral, Arbous, \& Steyerberg}]{de2023predicting}
\textsc{de~Hond}, A.~A., I.~M. \textsc{Kant}, M.~\textsc{Fornasa},
  G.~\textsc{Cin{\`a}}, P.~W. \textsc{Elbers}, P.~J. \textsc{Thoral}, M.~S.
  \textsc{Arbous}, \& E.~W. \textsc{Steyerberg} (2023): \enquote{Predicting
  readmission or death after discharge from the icu: External validation and
  retraining of a machine learning model.}
\newblock \emph{Critical Care Medicine} \textbf{51(2)}: pp. 291--300.

\bibitem[{Hsu \& Lin(2002)}]{hsu2002comparison}
\textsc{Hsu}, C.-W. \& C.-J. \textsc{Lin} (2002): \enquote{A comparison of
  methods for multiclass support vector machines.}
\newblock \emph{IEEE transactions on Neural Networks} \textbf{13(2)}: pp.
  415--425.

\bibitem[{Igareta(2021)}]{igareta2021strat}
\textsc{Igareta}, A. (2021): \enquote{Stratified sampling: You may have been
  splitting your dataset all wrong.}

\bibitem[{Japkowicz \& Shah(2011)}]{japkowicz2011evaluating}
\textsc{Japkowicz}, N. \& M.~\textsc{Shah} (2011): \emph{Evaluating learning
  algorithms: a classification perspective}.
\newblock Cambridge University Press.

\bibitem[{Kaushik(2016)}]{kaushik2016introduction}
\textsc{Kaushik}, S. (2016): \enquote{Introduction to feature selection methods
  with an example (or how to select the right variables?).}
\newblock Accessed: April 30, 2023.

\bibitem[{Kornbrot(2014)}]{kornbrot2014point}
\textsc{Kornbrot}, D. (2014): \enquote{Point biserial correlation.}
\newblock \emph{Wiley StatsRef: Statistics Reference Online} .

\bibitem[{Leskovec \emph{et~al.}(2020)Leskovec, Rajaraman, \&
  Ullman}]{leskovec2020mining}
\textsc{Leskovec}, J., A.~\textsc{Rajaraman}, \& J.~D. \textsc{Ullman} (2020):
  \emph{Mining of massive data sets}.
\newblock Cambridge university press.

\bibitem[{Lin \emph{et~al.}(2007)Lin, Lin, \& Weng}]{lin2007note}
\textsc{Lin}, H.-T., C.-J. \textsc{Lin}, \& R.~C. \textsc{Weng} (2007):
  \enquote{A note on platt’s probabilistic outputs for support vector
  machines.}
\newblock \emph{Machine learning} \textbf{68}: pp. 267--276.

\bibitem[{Malley \emph{et~al.}(2011)Malley, Kruppa, Dasgupta, Malley, \&
  Ziegler}]{randomforestmalley}
\textsc{Malley}, J., J.~\textsc{Kruppa}, A.~\textsc{Dasgupta},
  K.~\textsc{Malley}, \& A.~\textsc{Ziegler} (2011): \enquote{Probability
  machines consistent probability estimation using nonparametric learning
  machines.}
\newblock \emph{Methods of information in medicine} \textbf{51}: pp. 74--81.

\bibitem[{Marinov \& Karapetyan(2019)}]{marinov2019hyperparameter}
\textsc{Marinov}, D. \& D.~\textsc{Karapetyan} (2019): \enquote{Hyperparameter
  optimisation with early termination of poor performers.}
\newblock In \enquote{2019 11th Computer Science and Electronic Engineering
  (CEEC),} pp. 160--163. IEEE.

\bibitem[{Meyer(2015)}]{meyer2015support}
\textsc{Meyer}, D. (2015): \enquote{Support vector machines.}
\newblock \emph{The Interface to libsvm in package e1071} \textbf{28}: p.~20.

\bibitem[{Mucherino \emph{et~al.}(2009)Mucherino, Papajorgji, \&
  Pardalos}]{mucherino2009data}
\textsc{Mucherino}, A., P.~\textsc{Papajorgji}, \& P.~M. \textsc{Pardalos}
  (2009): \emph{Data mining in agriculture}, volume~34.
\newblock Springer Science \& Business Media.

\bibitem[{Navas-Palencia(2020)}]{navas2020optimal}
\textsc{Navas-Palencia}, G. (2020): \enquote{Optimal binning: mathematical
  programming formulation.}
\newblock \emph{arXiv preprint arXiv:2001.08025} .

\bibitem[{Newson(2002)}]{newson2002parameters}
\textsc{Newson}, R. (2002): \enquote{Parameters behind “nonparametric”
  statistics: Kendall's tau, somers’ d and median differences.}
\newblock \emph{The Stata Journal} \textbf{2(1)}: pp. 45--64.

\bibitem[{Newson(2014)}]{newson2014interpretation}
\textsc{Newson}, R.~B. (2014): \enquote{Interpretation of somers' d under four
  simple models.}

\bibitem[{Nian(2018)}]{nian2018introduction}
\textsc{Nian}, R. (2018): \enquote{An introduction to {ADASYN} (with code!).}
\newblock Medium.
\newblock Retrieved on May 2, 2023 from
  \url{https://medium.com/@ruinian/an-introduction-to-adasyn-with-code-1383a5ece7aa}.

\bibitem[{Owen(2022)}]{owen2022hyperparameter}
\textsc{Owen}, L. (2022): \emph{Hyperparameter Tuning with Python}.
\newblock Packt Publishing, 1st edition.
\newblock Original work published 2022.

\bibitem[{Patle \& Chouhan(2013)}]{patle2013svm}
\textsc{Patle}, A. \& D.~S. \textsc{Chouhan} (2013): \enquote{Svm kernel
  functions for classification.}
\newblock In \enquote{2013 International Conference on Advances in Technology
  and Engineering (ICATE),} pp. 1--9. IEEE.

\bibitem[{Platt \emph{et~al.}(1999)}]{platt1999probabilistic}
\textsc{Platt}, J. \emph{et~al.} (1999): \enquote{Probabilistic outputs for
  support vector machines and comparisons to regularized likelihood methods.}
\newblock \emph{Advances in large margin classifiers} \textbf{10(3)}: pp.
  61--74.

\bibitem[{Provost \& Fawcett(2013)}]{provost2013data}
\textsc{Provost}, F. \& T.~\textsc{Fawcett} (2013): \emph{Data Science for
  Business: What you need to know about data mining and data-analytic
  thinking}.
\newblock " O'Reilly Media, Inc.".

\bibitem[{Ribeiro \emph{et~al.}(2016)Ribeiro, Singh, \&
  Guestrin}]{ribeiro2016should}
\textsc{Ribeiro}, M.~T., S.~\textsc{Singh}, \& C.~\textsc{Guestrin} (2016):
  \enquote{" why should i trust you?" explaining the predictions of any
  classifier.}
\newblock In \enquote{Proceedings of the 22nd ACM SIGKDD international
  conference on knowledge discovery and data mining,} pp. 1135--1144.

\bibitem[{{scikit-learn}(2023)}]{sfs}
\textsc{{scikit-learn}} (2023): \enquote{Sequentialfeatureselector.}
\newblock
  \url{https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html#sklearn.feature_selection.SequentialFeatureSelector}.
\newblock Retrieved April 28, 2023.

\bibitem[{Tatsat \emph{et~al.}(2020)Tatsat, Puri, \&
  Lookabaugh}]{tatsat2020machine}
\textsc{Tatsat}, H., S.~\textsc{Puri}, \& B.~\textsc{Lookabaugh} (2020):
  \emph{Machine Learning and Data Science Blueprints for Finance}.
\newblock O'Reilly Media.

\bibitem[{TIBCO-Software(2023)}]{TIBCO2023}
\textsc{TIBCO-Software} (2023): \enquote{What is a random forest?}
\newblock \url{https://www.tibco.com/reference-center/what-is-a-random-forest}.
\newblock Retrieved April 30, 2023.

\bibitem[{Verma(2020)}]{Verma2020}
\textsc{Verma}, V. (2020): \enquote{A comprehensive guide to feature selection
  using wrapper methods in python.}
\newblock
  \url{https://www.analyticsvidhya.com/blog/2020/10/a-comprehensive-guide-to-feature-selection-using-wrapper-methods-in-python/}.
\newblock Retrieved April 30, 2023.

\bibitem[{Verma(2021)}]{Verma2021}
\textsc{Verma}, Y. (2021): \enquote{A complete guide to sequential feature
  selection.}
\newblock
  \url{https://analyticsindiamag.com/a-complete-guide-to-sequential-feature-selection/}.
\newblock Retrieved April 28, 2023.

\bibitem[{Wang(2020)}]{wang2020bayesian}
\textsc{Wang}, W. (2020): \enquote{Bayesian optimization concept explained in
  layman terms.}
\newblock Medium.
\newblock Accessed: April 29, 2023.

\bibitem[{Wendler \& Gr{\"o}ttrup(2021)}]{wendler2021data}
\textsc{Wendler}, T. \& S.~\textsc{Gr{\"o}ttrup} (2021): \emph{Data Mining with
  SPSS Modeler: Theory, Exercises and Solutions}.
\newblock Cham: Springer.

\bibitem[{Witten \emph{et~al.}(2011)Witten, Frank, Hall, \&
  Pal}]{witten2011data}
\textsc{Witten}, I.~H., E.~\textsc{Frank}, M.~\textsc{Hall}, \& C.~\textsc{Pal}
  (2011): \emph{Data Mining: Practical Machine Learning Tools and Techniques}.
\newblock Morgan Kaufmann, 4th edition.

\bibitem[{Witzany(2017)}]{witzany2017credit}
\textsc{Witzany}, J. (2017): \emph{Credit risk management}.
\newblock Springer.

\bibitem[{Zeng(2014)}]{zeng2014necessary}
\textsc{Zeng}, G. (2014): \enquote{A necessary condition for a good binning
  algorithm in credit scoring.}
\newblock \emph{Applied Mathematical Sciences} \textbf{8(65)}: pp. 3229--3242.

\end{thebibliography}
