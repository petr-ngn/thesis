\chapter{Conclusion}
\label{conclusion}

The main contribution of this thesis is to develop a custom machine learning implementation framework using Python which is further applied to the application scoring data set of US home equity loans (HMEQ).
In this thesis, we employ 8 classification models: Logistic Regression, Decision Tree, Gaussian Naive Bayes, K--Nearest Neighbors, Random Forest, Gradient Boosting, Support Vector Machine, and Neural Network. As evaluation metrics, we use F1, Precision, Recall, Accuracy, Matthews Correlation Coefficient, AUC, Kolmogorov--Smirnov Distance, Somers' D, Brier Score Loss and Log Loss.
Prior the machine learning implementation, we cover theoretical background of both credit risk and machine learning (\autoref{chap:two}), and we also propose five hypotheses (\autoref{chap:three}), including the literature review with the main focus on HMEQ--based studies of Aras \citep{serkan2021bagging} and Zurada \citep{zurada2014classification}.

Within the empirical analysis (\autoref{chap:four}) we conduct machine learning implementation on HMEQ data set, which includes data exploration, data preprocessing, hyperparameter tuning, feature selection, model selection, model recalibration, model evaluation and final machine learning deployment.
In the data exploration (\autoref{sec:dataexploration}), we inspect the distributions of the variables and their associations.
Within the data preprocessing phase (\autoref{sec:dataprep}), we perform 3 operations: (1) Stratified split into training, validation  and test set with 70:15:15 ratio, (2) ADASYN oversampling for balancing default distribution, and (3) Optimal Binning of features and Weight--of--Evidence transformation.

In the ML modelling (\autoref{sec:modelling}), we establish hyperparameter tuning process using Bayesian Optimization with 50 iterations, stratified 10--fold cross validation while maximizing F1 score (\autoref{subsec:hyperoptbayes}).
Such process enters into 2 following steps: feature selection and model selection.
In the former step (\autoref{subsec:feature-selection}), each model is tuned with Bayesian Optimization and is further used within Forward Sequential Feature Selection, which returns a subset of optimal features. The features are selected while maximizing F1 score using the stratified 10--fold cross validation. Since we have 8 models, we get 8 subsets of features.
In the latter step (\autoref{subsec:modelselection}), each model is tuned on each subset of selected features, and then evaluated on the validation set by computing a range of metrics mentioned above. Instead of using standard classification threshold 0.5, we calculate an optimal threshold using Youden index. Since we have 8 models and 8 subsets of features, we obtain 64 models.

Each metric is used to rank all the models, and the rank score is then calculated as a weighted average of the individual rankings, with the author's explicit weights. We calculate the final rank based on the rank score.
The final model chosen for evaluation and deployment is the one with the highest rank (rank of 1). 
The final model is \textbf{Gradient Boosting} which was trained on the features selected by \textbf{Neural Network}.
Such final model and its threshold are recalibrated on the joined training and validation set prior the evaluation (\autoref{subsec:modelrecal}).
In the evaluation part (\autoref{sec:modeleval}), we assess the model's performance on test set, inspect the impact of the recalibration on the model's performance and delve into black--box model explainability using feature importances and SHAP values.
It is evident that debt--to--income ratio and number of delinquent credit lines are the main default drivers.

Prior the deployment of the model into a production (\autoref{sec:deployment}), the final model and its optimal threshold are recalibrated on the whole data set in order to maximize the predictive power of the model.
Particularly, we develop a web application using Flask and HTML, which is temporarily deployed on PythonAnywhere cloud platform and available via the following link: \url{http://ml-credit-risk-app-petrngn.pythonanywhere.com/}.
Such application requires to fill in the loan application form  (\autoref{fig:flaskform}) and once the form is submitted, the application processes the inputs and returns (1) loan approval result (2), predicted probability of default and (3) local black--box model explainability of the prediction using LIME (\autoref{fig:flaskres}).

Lastly, we summarize our results (\autoref{chap:five}), particularly we assess the hypotheses' testing in conduct a comparison with the HMEQ--based studies, outline key findings and main contributions, and propose several policy recommendations for feature research.