\chapter{Summary of Results}
\label{chap:five}
In this chapter, we evaluate the hypotheses presented in \autoref{sec:hypotest}, as outlined in \autoref{sec:hypo}.
These evaluations are based on the results obtained from the implementation of machine learning techniques described in \autoref{chap:four}. 
Furthermore, we compare our results with those of previous studies on HMEQ--based studies \citep{serkan2021bagging,zurada2014classification} in \autoref{sec:comparisonfinal}.
Additionally, we provide a summary of the key findings derived from the machine learning implementation from \autoref{chap:four} in  \autoref{sec:keyfindings}. 
Moreover, we delve into the author's contributions to the field of credit risk modelling and machine learning in \autoref{sec:contributions}.
Lastly, we address the key recommendations to improve this thesis and its machine learning implementation or for future research in \autoref{sec:recommendations}.

\section{Hypotheses' Testing}
\label{sec:hypotest}
\noindent \textbf{Result \#1:} \textit{The recalibration of the model \underline{DOES} enhace model performance on HMEQ data set.}

We fail to reject the \textbf{Hypothesis \#1} because we observe improvements across all the metrics within evaluation on test set when the final model was re-trained on the joined training and validation set instead solely on the training set.
In particular, all the score metrics and loss metrics have increased and decreased, respectively, as can be seen in \autoref{tab:recab}. Hereby, we can confirm that the recalibration of the model truly boost the model predictive power on HMEQ data set.

\vspace{0.3cm}

\noindent \textbf{Result \#2:} \textit{Neural Network and KNN model \underline{DO NOT} outperform all the models on HMEQ data set.}

We reject the \textbf{Hypothesis \#2} as the final model, which is the best performing, is the Gradient Boosting model as described in \autoref{tab:finalmodelinfo}.
KNN was also outperformed by the Random Forest and in case of Neural Network, it was outperformed by SVM as well, as can be seen in \autoref{fig:avgrankdist}.
If we aggregate the model selection results by looking the highest rank per each model, we can observe that the best KNN model had the 12th highest rank, while Neural Network (MLP) exhibited unsatisfactory performance with the 26th highest rank as can be seen in \autoref{tab:maxranks}.
Therefore, our results are not in with line with the outcomes of respective studies \citep{serkan2021bagging,zurada2014classification} which reported that Neural Network and KNN model outperformed all the models on HMEQ data set, respectively.

\begin{table}[H]
    \small
    \setlength{\tabcolsep}{8pt}
    \renewcommand{\arraystretch}{1.3}
    \centering
        \caption[Max--Aggregated Ranks of Models]{Max--Aggregated Ranks of Models}\label{tab:maxranks}
        \begin{tabular}{r r}
    \toprule
    \textbf{Model} & \textbf{Rank}\\
    \midrule
    \hline
    GB & 1 \\ 
    RF & 6 \\ 
    KNN & 12 \\ 
    SVM & 17 \\ 
    MLP & 26 \\ 
    DT & 35 \\ 
    LR & 39 \\
    GNB & 52 \\
    \hline
    \bottomrule
    \end{tabular}
    \vspace{0.35em}

        \centering{\begin{source}Author's results in Python\end{source}}\vspace{-1em}
\end{table}

\vspace{0.3cm}

\noindent \textbf{Result \#3:} \textit{Black--box models \underline{DO} perform better than the white--box models on HMEQ data set.}

We fail to reject the \textbf{Hypothesis \#3} as the black--box models truly outperformed the white--box models as can be seen in \autoref{fig:avgrankdistbbwb}, which depicts the distribution of ranks for both black--box and white--box models.
Most of the white--box models were ranked in the bottom half within the model selection, whereas the 10 best performing models consisted out of black--box models only, namely Gradient Boosting and Random Forest.
Even though that some black--box models' performances were weak and other white--box models exhibited relatively high ranks, we can still conclude that the black--box models outperformed the white--box models on average as the median of the black--box models' ranks is lower than the white--box models' median.
\vspace{0.3cm}

\noindent \textbf{Result \#4:} \textit{The longer execution time of a model \underline{DOES NOT} indicate better performance on HMEQ data set.}

We reject the \textbf{Hypothesis \#4} as according to \autoref{fig:timedist}, even though the Neural Network (MLP) model had the longest execution time on average, it underperformed several models such as Gradient Boosting, Random Forest, KNN and SVM which took significantly less time to execute. The same can be observed from \autoref{fig:scattertime}, where Neural Network performed poorly regardless the length of the execution time.
\vspace{0.3cm}

\noindent \textbf{Result \#5:} \textit{Debt and delinquency features \underline{ARE} the main default drivers on HMEQ data set.}

We fail to reject the \textbf{Hypothesis \#5} according to \autoref{fig:fi} which depicts the feature importance of the final model (Gradient Boosting). As can be seen, the most important features are debt--to--income ratio \texttt{DEBTINC} and number of delinquent credit lines \texttt{DELINQ}.
Based on the SHAP values depicted in \autoref{fig:shap}, we can observe that the negative values of \texttt{DEBTINC} and \texttt{DELINQ} positively contribute to the model's predictions of the target variable, whereas the positive values negatively contribute to the model's predictions.
In other words, the higher value of such features, the higher probability of default and vice versa.
Since the features' values are encoded as WoE, the negative WoE values indicates larger distribution of defaulters compared to non--defaulters in given bins.
Based on the WoE bins distribution in \autoref{fig:woedistdebtinc} and \autoref{fig:woedistdelinq}, respectively, we can observe negative WoE values for bins where the debt--to--income ratio is extremely high or is missing and regarding to the number of delinquent credit lines, we can observe a negative WoE value for bin corresponding to the relatively high number of delinquent credit lines.
Therefore, if the loan applicant has either high or missing debt--to--income ratio and/or relatively high number of delinquent credit lines, he would be likely to default.

\newpage
\section{Comparison with other HMEQ Studies}
\label{sec:comparisonfinal}
Within the literature review in \autoref{chap:three}, we disscused the studies of Aras \citep{serkan2021bagging} and Zurada \citep{zurada2014classification} which analyzed the HMEQ data set, i.e., the same data set as in this thesis.
In this section, we contrast their results with those of this thesis. Particularly, we compare the models' rankings from \autoref{tab:serkanresultsranks} and \autoref{tab:zuradaresultsranks}, respectively, with the thesis' author's rankings derived from \autoref{tab:maxranks}, which is summarized in the following \autoref{tab:comparisonfinal}.
Upon examination, it is apparent that none of the studies considered the Gradient Boosting model, which happens to be the best-performing model in this thesis.

With respect to the study of Aras \citep{serkan2021bagging}, when excluding our Gradient Boosting model, we can agree that Random Forest and KNN are the top-performing models. However, there is a discrepancy in the order of their performance. Aras found that KNN outperformed Random Forest, whereas in this thesis, Random Forest outperformed KNN.
Furthermore, it is worth noting that the worst-performing models, namely Decision Tree, Logistic Regression, and Gaussian Naive Bayes, align with both this thesis and Aras' study. Specifically, Aras identified Logistic Regression as the worst-performing model, while in this thesis, Gaussian Naive Bayes exhibited the poorest performance.

Regarding the Zurada's study \citep{zurada2014classification}, we again concur that Logistic Regression is one of the worst performing models.
However, there are significant disparities in the rankings of other models compared to the results obtained in this thesis.
It is evident from the findings that MLP was identified as the best performing model in Zurada's study, whereas in this thesis, MLP was ranked as the 5th best performing model, placing it in the second half of the ranked models.
In contrast, while KNN was ranked as the 3rd best performing model in this thesis, it received the position of the 2nd worst performing model according to Zurada.
Conversely, Zurada ranked Decision Tree as the best second performing model, while in this thesis, it was positioned as the 6th best performing model.
However, both Zurada's and Aras' studies, consistent with this thesis, ranked the SVM model in the middle range, aligning with our findings.
\begin{table}[H]
    \small
    \setlength{\tabcolsep}{8pt}
    \renewcommand{\arraystretch}{1.3}
    \centering
        \caption[Ranking Results Comparison based on HMEQ Data Set]{Ranking Results Comparison based on HMEQ Data Set}\label{tab:comparisonfinal}
        \begin{tabular}{r r r r}
    \toprule
    \textbf{Model} & \textbf{This Thesis} & \textbf{\citep{serkan2021bagging}} & \textbf{\citep{zurada2014classification}}\\
    \midrule
    \hline
    GB & 1 & - & - \\ 
    RF & 2 & 2 & - \\ 
    KNN & 3 & 1 & 4 \\ 
    SVM & 4 & 3 & 3 \\ 
    MLP & 5 & - & 1 \\ 
    DT & 6 & 4 & 2 \\ 
    LR & 7 & 6 & 5 \\
    GNB & 8 & 5 & - \\
    \hline
    \bottomrule
    \end{tabular}
    \vspace{0.35em}

        \centering{\begin{source}Author's results in Python, Rankings of \citep{serkan2021bagging}, \citep{zurada2014classification}\end{source}}\vspace{-1em}
\end{table}

It is important to note that the author of the thesis, Aras, and Zurada employed distinct data preprocessing techniques and different data splits, leading to variations in the training, tuning, and evaluation samples, resulting in disparate outcomes.
While Zurada and Aras utilized Grid Search with cross-validation for hyperparameter tuning, the author of the thesis employed Bayesian Optimization with stratified cross-validation. Besides, each author used different hyperparameters' spaces.

Additionally, each author utilized different evaluation metrics. Aras utilized Accuracy, Recall, Precision, F1, and Matthews Correlation Coefficient, while Zurada employed Accuracy, Recall, and AUC.
In contrast, the author of the thesis employed a broader range of metrics, including Accuracy, Recall, Precision, F1, Matthews Correlation Coefficient, AUC, Kolmogorov-Smirnov Distance, Somers' D, Brier Score Loss, and Log Loss.
Moreover, it is worth mentioning that the authors may have used different software tools. The thesis' author utilized Python, while Zurada employed Weka, and the software used by Aras is unknown.
These various factors contribute to the discrepancies in the obtained results among the studies and the thesis. Therefore, it is advisable to refrain from making direct comparisons due to the incomparability of the results.
\vspace{0.3cm}

\newpage
\section{Key Findings}
\label{sec:keyfindings}
The key findings of this thesis are summarized in the following list. We exclude such findings which are derived from the hypotheses' testing in \autoref{sec:hypotest}, namely that the most important features for predicting default are the number of delinquent credit lines \texttt{DELINQ} and the debt--to--income ratio \texttt{DEBTINC}, and that the Gradient Boosting model outperforms all other models in terms of the majority of evaluation metrics etc.

\begin{itemize}\setlength\itemsep{0em}
    \item ADASYN oversampling generates more default--case instances which are managers according to \texttt{JOB} feature as described in depicted in \autoref{tab:adasynimpact} and \autoref{fig:adasynimpact}.
    This is attributed to ADASYN nature as it generates more synthetic instances for such default--case instances which are hard-to--learn, therefore default clients who are managers are hard--to--learn according to ADASYN and its underlying KNN algorithm as described in \autoref{subsec:data-split-ADASYN}. By generating more synthetic learn for instances which are hard--to--learn, ADASYN oversampling is expected to improve the model's performance.
    \item We can also observe the impact of missing values within default prediction, particularly in case of debt--to--income ratio \texttt{DEBTINC}. As can be seen in \autoref{fig:woedistdebtinc}, the WoE corresponding the bin capturing missing values has a negative value of (approx. -2), which indicates a larger distribution of defaulters compared to non--defaulters.
    Referring to the WoE values, the SHAP summary plot (\autoref{fig:shap}) depicts the global model explainability and the contribution of each feature to the predictions. As can be seen in case of \texttt{DEBTINC}, the blue values (i.e., negative WoE values) contributes positively to the default, hence when the debt--to--income ratio is missing, the model is more likely to predict default for such instance.
    \item Another finding regards the features \texttt{DEBTINC} and \texttt{DELINQ}. The higher debt--to--income ratio and/or the higher number of delinquent credit lines, the higher the probability of default. This is evident from the WoE values in \autoref{fig:woedistdebtinc} and \autoref{fig:woedistdelinq}, respectively, and the SHAP summary plot in \autoref{fig:shap}.
    \item Most of the models are conservative as most of their optimal thresholds obtained using Youden index are below the standard classification threshold of 0.5 as depicted in \autoref{fig:thresdistclean}.
    \item Ensemble models, such as Gradient Boosting and Random Forest, perform better than SVM or Neural Network (MLP), while the transparent models such as Decision Tree, Logistic Regression, and Gaussian Naive Bayes perform the worst. This is depicted in \autoref{fig:avgrankdist}.
    \item Black--box models which are complex tend to select more features than transparent white box--models within feature selection (\autoref{fig:fsrec}).
\end{itemize}
\section{Contributions}
\label{sec:contributions}
The primary contribution of the thesis author involves the implementation of a customized machine learning framework on a credit risk dataset consisting of performing and non-performing US home equity loans, as described in \autoref{fig:mlframe} from high--level point of view. This framework encompasses several key steps.

Firstly, the author conducts data exploration (\autoref{sec:dataexploration}), including distribution and association analysis. To address the imbalanced distribution of defaults, an advanced approach utilizing ADASYN oversampling is employed (\autoref{subsec:data-split-ADASYN}).
Additionally, a preprocessing step utilizing Optimal Binning is implemented to discretize feature values into bins optimized with respect to the default status, while also capturing the impact of extreme and missing values by converting them into Weight-of-Evidence values (\autoref{subsec:prep-optbinning}).

The author then utilizes custom wrapped algorithms for both feature selectionand model selection.
These algorithms incorporate Bayesian Optimization for hyperparameter tuning based on the chosen classification models (\autoref{subsec:hyperoptbayes}).
Within the feature selection, algorithm, each model is tuned and used within Forward Sequential Feature Selection to determine the subset of optimal features  (\autoref{subsec:feature-selection}).
Within the model selection algorithm, each model is tuned and trained on subsets of selected features, determining an optimal threshold for classification using the Youden index, and subsequently evaluated on a validation set using a variety of metrics (\autoref{subsec:modelselection}).
The models are ranked based on these metrics, considering explicit weights defined by the author.
The best performing model is selected for final evaluation on the test set and for deployment.

To enhance the model's performance and generalization ability, the author performs recalibration of the model and threshold prior to evaluation, by joining the training and validation sets into one set used for model recalibration (\autoref{subsec:modelrecal}).
The evaluation process encompasses various approaches, including the assessment of the model's performance using a confusion matrix, evaluation metric scores and losses, and ROC curve analysis (\autoref{subsec:modelperformance}).
The impact of recalibration on the evaluation is also examined.
Additionally, the author assesses the explainability of the black-box model by analyzing feature importances and SHAP values (\autoref{subsec:explainability}).

Another significant contribution involves deploying the model as a web application using Flask and HTML (\autoref{sec:deployment}).
The deployed application is recalibrated alongside its threshold on the joined training, validation and test sets to enhace model's ability to generalize.
Such application is temporarily hosted and deployed on PythonAnywhere cloud platform and made publicly accessible.
Users are required to complete a loan application form, with the fields corresponding to the features on which the model was trained.
After submission, the application provides a result and default prediction, accompanied by explainability insights using LIME, which highlights the contribution of each feature to the prediction (\autoref{subsec:flaskapp}).


\section{Recommendations}
\label{sec:recommendations}
Despite the complexity of the custom machine learning solution applied in this thesis, and the hundreds of hours invested by the author, it still has its limitations and drawbacks. We aim to address these issues in this section and provide suggestions for future studies.
\begin{enumerate}\setlength\itemsep{0em}
    \item \textbf{Use more relevant and actual data} - Given the nature of the data set analyzed in this thesis, it might not be the most relevant for the current market situation. Thus, using an up-to-date data would either lead to a more realistic generalization \citep {kumar2021blockchain} or an improvement in model's performance \citep{karatas2020increasing}.
    \item \textbf{Use bigger data} - Since the real bank data sets often contain hunders of thousands or even millions of instances, and the number of features can be in hundreds or even higher, it would be beneficial to use bigger data sets to train the models on. Therefore, having bigger sample size for the training, we can enhace model's performance \citep{ng2020influence}, as the model would be able to learn more complex patterns in the data. 
    \item \textbf{Use behavioral scoring data} - The data set used in this thesis is based on the application data only, however, the behavioral scoring data is often used in the real--world applications as well. Therefore, it would be also beneficial to use behavioral scoring data which would dynamically capture the client's information about his behavior and it would help the bank to make more informed decision about how to deal with the existing clients \citep{li2012overview}.
    \item \textbf{Use macroeconomic data} - Using macroeconomic data such as GDP, unemployment rate, inflation rate, interest rate etc. would allow to create macroeceonomic forecasts, i.e., to take into account possible changes in the macroeconomic changes by incorporating forward--looking information \citep{jakubik2007macroeconomic}.
    Thanks to that, one would be able to achieve more more reliable estimates by would dynamically capturing the current economic situation.
    \item \textbf{Use TensorFlow/Keras or PyTorch for NN development} - In this thesis, we used Neural Network (Multi--Layer Percepton) from \lstinline{Scikit-learn} module. Howeover, in ML engineering or deep learning, the Neural Networks are mostly developed using TensorFlow/Keras or Keras modules which are more efficient and provide more flexibility \citep{gevorkyan2019review}.
    \item \textbf{Django for ML deployment} - In this thesis, a Flask framework was used for ML deployment as a web application. Although Flask is a great tool for ML deployment when it comes to the small projects or micro-framework solutions, it is not suitable for production environment.
    Therefore, we recommend to use Django framework for ML deployment, which is a full--stack Python--based web application framework and is more suitable for production environment and creating larger more complex database--backed websites and applications \citep{khatri2023}.
    \item \textbf{ML implementation in other credit risk modelling components} - Besides applying ML prediction models in credit risk for default prediction (i.e., PD), it would be also beneficial to apply ML models in other credit risk modelling components such as LGD and EAD, ECL \citep{munkhdalai2019empirical, grzybowska2020application} or even for macroeceonomic forecasting \citep{hall2018machine}.
    \item \textbf{Hyperparameter Optimization with Optuna} - In this thesis, we used Bayesian Optimization from \lstinline{Scikit-optimize} module for hyperparameter optimization. However, there are more efficient framwork, namely Optuna module, which is deemed as the next--generation hyperparameter optimization software which allows to construct the hyperparameter search space dynamically, efficient implementation of searching and pruning strategies and it also provides
    a versatile architecture which can be deployed in scalable distributed computing or light--weight experiments conducted through interactive interface \citep{akiba2019optuna}.
    \item \textbf{H2O ML library} - H2O is an automated machine learning library which is more efficient than \lstinline{Scikit-learn} and provides more flexibility in terms of faster scoring capabilities or producing high quality models suitable for deployment in enterprise envinronment \citep{ledell2020h2o}. 
    According to H2O's documentation, it provides wrapper functions which perform a large number of modelling-related tasks that would typically require many lines of code and it can be also used for automating the machine learning workflow including automatic training and tuning of many models \citep{H2Oai2023}.
\end{enumerate}